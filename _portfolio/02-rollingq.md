---
title: "RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer"
excerpt: "ICML 2025 - Investigating cooperation dynamics in multimodal transformers<br/><img src='/images/rollingq.png' width='500'>"
collection: portfolio
date: 2025-06-08
---

## RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer

**Accepted to ICML 2025**

### Overview
This project investigates the cooperation dynamics between different modalities in multimodal transformers and proposes RollingQ, a novel approach to enhance cross-modal understanding and generation capabilities.

![RollingQ Framework](/images/rollingq.png)

### Key Contributions
- Discovered that dynamic adaptability of widely-used self-attention models diminishes during training
- Identified a self-reinforcing cycle that progressively overemphasizes the favored modality
- Proposed Rolling Query (RollingQ) to balance attention allocation and restore cooperation dynamics
- Validated effectiveness across various multimodal scenarios

### Links
- ðŸ“„ [arXiv Paper](https://arxiv.org/abs/2506.11465)
- ðŸ’» [Code](https://github.com/Angusliuuu/RollingQ) (Coming soon)
- ðŸ“Š [Project Page](#) (Coming soon)

### Authors
Haotian Ni, Yake Wei, **Hang Liu**, Gong Chen, Chong Peng, Hao Lin, Di Hu

### Publication
Accepted to **International Conference on Machine Learning (ICML), 2025**

